---
layout: home
hero:
  name: xtrace
  text: AI Observability Service
  tagline: Collect, store, and query traces, spans, and metrics across LLM and agent workflows. Built in Rust for speed and reliability.
  actions:
    - theme: brand
      text: Get Started â†’
      link: /guide/getting-started
    - theme: alt
      text: View on GitHub
      link: https://github.com/lipish/xtrace
  image:
    src: /logo.svg
    alt: xtrace

features:
  - icon: ğŸ”­
    title: Traces & Spans
    details: Full request-chain visibility with nested span trees. Debug P3 cycles (Plan â†’ Execute â†’ Reflect) and multi-step agent workflows.
  - icon: ğŸ“Š
    title: Time-Series Metrics
    details: Ingest and query GPU utilization, KV cache, token usage, and custom metrics with label-based filtering and downsampling.
  - icon: âš¡
    title: Built in Rust
    details: Axum + Tokio async runtime, batched ingestion via mpsc channels, PostgreSQL storage. Sub-millisecond overhead on the write path.
  - icon: ğŸ”—
    title: OpenTelemetry Compatible
    details: OTLP/HTTP ingestion endpoint with JSON and Protobuf support. Drop-in replacement for Langfuse-compatible instrumentation.
  - icon: ğŸ·ï¸
    title: Multi-Dimensional Labels
    details: Attach session_id, model_name, agent_role, and arbitrary labels to metrics. Filter and group by any dimension.
  - icon: ğŸ“ˆ
    title: Percentile Analytics
    details: Query p50/p90/p99 latency distributions. Compare performance across versions, models, and agent configurations.
---
